{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"cols = ['MPG','Cylinders','Displacement','Horsepower','Weight','Acceleration','Model Year','Origin']\n\ndf = pd.read_csv('../input/autompgdata/auto-mpg.data',names=cols,na_values=\"?\",comment='\\t',sep=\" \",skipinitialspace=True)\n\ndata=df.copy()\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(data, data[\"Cylinders\"]):\n    strat_train_set = data.loc[train_index]\n    strat_test_set = data.loc[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = strat_train_set.drop('MPG',axis=1)\ndata_labels = strat_train_set['MPG'].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_origin_cols(df):\n    df['Origin'] = df['Origin'].map({1: \"India\", 2: \"USA\",3: \"Germany\"})\n    return df\ndata_tr = preprocess_origin_cols(data)\ndata_tr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cat = data_tr[[\"Origin\"]]\ndata_cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\ncat_encoder = OneHotEncoder()\ndata_cat_1hot = cat_encoder.fit_transform(data_cat)\ndata_cat_1hot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cat_1hot.toarray()[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_data = data.iloc[:,:-1]\nnum_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(strategy=\"median\")\nimputer.fit(num_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imputer.statistics_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = imputer.transform(num_data)\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_tr = pd.DataFrame(X, columns=num_data.columns,index=num_data.index)\ndata_tr.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\nacc_ix, hpower_ix, cyl_ix = 4,2,0\n\nclass CustomAttrAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, acc_on_power=True):\n        self.acc_on_power = acc_on_power\n    def fit(self,X,y=None):\n        return self\n    def transform(self,X):\n        acc_on_cyl = X[:, acc_ix] / X[:, cyl_ix]\n        if self.acc_on_power:\n            acc_on_power = X[:,acc_ix] / X[:, hpower_ix]\n            return np.c_[X, acc_on_power,acc_on_cyl]\n        return np.c_[X, acc_on_cyl]\n\nattr_adder = CustomAttrAdder(acc_on_power=True)\ndata_tr_extra_attrs = attr_adder.transform(data_tr.values)\ndata_tr_extra_attrs[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\n\nfrom sklearn.preprocessing import StandardScaler\n\nnumerics = ['float64','int64']\n\nnum_data = data_tr.select_dtypes(include=numerics)\n\nnum_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy=\"median\")),\n    ('attrs_adder', CustomAttrAdder()),\n    ('std_scalar', StandardScaler()),\n])\n\nnum_data_tr = num_pipeline.fit_transform(data_tr)\nnum_data_tr[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\n\nnum_attrs = list(num_data)\ncat_attrs = [\"Origin\"]\n\nfull_pipeline = ColumnTransformer([\n    (\"num\", num_pipeline, num_attrs),\n    (\"cat\", OneHotEncoder(), cat_attrs),\n])\n\nprepared_data = full_pipeline.fit_transform(data)\nprepared_data","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}